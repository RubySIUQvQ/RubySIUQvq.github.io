---
title: '深入浅出决定系数R2'
date: 2024-11-06T15:48:37+08:00
draft: false
ShowToc: true
TocOpen: true
typora-root-url: ..\..\..\static
---

决定系数$R^2$是一个在数学或者说统计学常见的评价标准，尤其是对于回归问题，模型的好坏完全可以用只通过$R^2$来衡量。

但是在使用这个指标之前我们有必要了解其背后的原理，尤其是和另一个非常容易混淆的相关系数$R$的关系。

## 一、回归问题

相关系数和决定系数都是评价回归模型的指标，因此我们先了解什么是回归问题。

所谓回归就是研究一组随机变量$Y_1,Y_2...Y_n$和另一组随机变量$X_1,X_2...X_n$之间的关系的统计分析方法。通常我们可以将两组变量的关系简单的划分为线性和非线性，对应的就是线性回归和非线性回归。简单地说线性回归下两组随机变量之间的关系基本可以使用一条直线来表示，而不能使用直线表示的就是非线性回归。

## 二、相关系数

相关系数有很多不同的定义，例如最常用的 Pearson 相关系数用于衡量两个变量之间的线性关系，Spearman 相关系数用于衡量两个变量之间的单调关系。

此处只讨论最常用的 Pearson 相关系数，其计算公式如下：
$$
r=\frac{\sum(x_i-\bar x)(y_i-\bar y)}{\sqrt{\sum(x_i-\bar x)^2\sum(y_i-\bar y)^2}}
$$
其中$\bar x, \bar y$分别表示样本的平均值。实际上该公式可以简化为两个变量的协方差与两个变量方差乘积的比值。但我们不想在此处深入讨论该公式的含义，我们只需要知道相关系数的取值范围在 -1 到 1 范围内，越接近 1 表示正相关，越接近 -1 表示负相关，接近 0 表示两者没有**线性相关性**。

## 三、决定系数

决定系数是衡量模型的拟合值或预测值与真实值之间的相似程度。

> 需要注意的是，相关系数衡量两个随机变量之间的线性相关性，实际上可以理解为衡量因变量和自变量之间的线性相关性。
>
> 但是决定系数是衡量真实样本的因变量和模型模拟的因变量之间的相似程度，两者在含义上完全不同

决定系数的公式如下：
$$
r^2=\frac{SSR}{SST}=1-\frac{SSE}{SST}\\

SST=SSR+SSE=\sum(y-\bar y)^2\\

SSR=\sum(\hat y-\bar y)^2\\

SSE=\sum(y-\hat y)^2
$$
 在线性回归问题中，可以代入$\hat y=ax+b$，推导后发现决定系数等于相关系数的平方。

但是在非线性回归问题中，不可以将两者划为平方关系，因为其计算方法和含义完全不同。

## 四、决定系数的深层含义

本文我们主要讨论决定系数，因此我们要了解一下决定系数到底评价了什么。

对于以下形式的决定系数计算公式：
$$
r^2=1-\frac{\sum(y-\hat y)^2}{\sum(y-\bar y)^2}
$$
我们对比另一个评价指标MSE：
$$
MSE=\frac{\sum(y-\hat y)^2}{n}
$$
假如我们将 $\bar y$也视为一个模型的预测，只是这个模型固定输出均值作为预测值。那么决定系数的分式项就可以理解为我们的模型和均值模型的预测值对真实值的方差之比，这个分式就衡量了我们的模型相比于均值模型的好坏程度。

这种说法可能比较别扭，我们换另一个思路来理解。

假设我们已经建立一个模型，现在我们想要评价一下他的性能，于是我们计算了MSE。我们知道均方误差的最小值为 0，因此 MSE=0 的时候模型是最好的，这代表模型的预测没有任何误差。但是 MSE 的上限在哪里呢？

很显然没有上限，我的模型完全可以天马行空的给出预测值。所以我们需要一个标准，能够限定 MSE 上限的标准。自然的，我们想到了均值模型，我们暂且称其为非熟练（unskilled）模型。我们规定 MSE 的上限应该是非熟练模型的 MSE，超过此值的模型应该是错误的或者完全不起作用的。

通过进行最大最小值归一化，我们将 MSE 缩放到了 0-1 之间，为了符合习惯，我们用 1 减去这个值，将最好模型指标设置为 1，最差的模型指标设置为 0。而均方根误差的除以样本数量的操作在分式中被抵消了，由此我们得到了相同的决定系数公式。此时决定系数就代表了熟练模型的拟合效果，其最高可以完全拟合，最低则相当于非熟练模型（此处为均值模型）。

但是很显然我们建立的模型可能效果还不如均值模型，所以决定系数实际上可以为负值，表示我们建立的模型不如直接使用均值。

## 五、决定系数的缺陷

前面我们说决定系数实际上和均值模型有关，而均值模型的均值是一个样本内指标，这是传统统计学的方法。但是机器学习要求我们在样本外进行评估。也许有人说，我们明明已经划分了训练集和测试集，所有的评估都是在测试集上进行的。但这其中仍然隐藏着数据泄露的问题，数据不是泄露给了机器学习模型，而是泄露给了均值模型。

当我们在测试集上计算决定系数的时候，我们使用测试集的样本均值作为了非熟练模型的结果，此时就发生了数据泄露问题。对于均值模型来说，他已经知道了测试集的均值，而我们的机器学习模型对测试集则是一无所知，这里就发生了数据泄露。因此决定系数使用均值模型来衡量机器学习模型的好坏是不公平的。

所以一个更好的指标是样本外决定系数（out of sample R square），我们不再使用测试集均值，而是使用**训练集均值**作为测试集均值模型的输出。此时均值模型对测试集也是一无所知的状态。这种方法可以更公平准确的判断模型的效果。
